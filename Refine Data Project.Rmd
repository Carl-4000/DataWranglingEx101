---
title: "Refine Data Exercise"
author: "Carl Larson"
date: "1/4/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Springboard Data Wrangling Exercise

Using R code, the objective is to operate on the refine_original.csv data file to clean the data in the following ways: 

#0. Load the data in RStudio
#1. Clean Up Brand Names
#2. Separate product code and number 
#3. Add product categories
#4. Add full address geocoding
#5. Create dummy variables for company and product category
#6. Submit the paper on Github

Note I was asked to convert an .xls file with the data to .csv before importing it to R, otherwise I would have used the read.xlsx function and applied it to an R dataframe.


```{r}
#0:
#Loading the data and R packages dplyr
suppressWarnings(suppressMessages(require("dplyr")))
suppressWarnings(suppressMessages(require("tidyr")))
rawdf = read.csv("/Users/EagleFace/Documents/refine_original.csv")
print(rawdf)
```

##1. Clean up brand names

Now that we have our dataframe loaded and displayed, we can address task 1 and clean up the various spelling mistakes in the first column. 

We can use the dplyr package's agrep() function to group the various misspellings into categories for the companies given. This computation is a basic algorithm based on error-pattern recognition, and setting an argument for the maximum number of allowable changes to a misspelled word. This also factors our results as categories, which is efficiently helpful.


```{r}
#1: 
#First we use the tbl_df function to write the raw data to a workable R dataframe. 
#We then write the goal pattern and assign them to the companies.  

df <- tbl_df(rawdf)
id_p <- agrep(pattern = "philips", x = df$company, ignore.case = TRUE, 
              value = FALSE, max.distance = 3)
id_a <- agrep(pattern = "akzo", x = df$company, ignore.case = TRUE, 
              value = FALSE, max.distance = 3)
id_v <- agrep(pattern = "van houten", x = df$company, ignore.case = TRUE, 
              value = FALSE, max.distance = 3)
id_u <- agrep(pattern = "unilever", x = df$company, ignore.case = TRUE, 
              value = FALSE, max.distance = 3)
df$company[id_p] <- "philips"
df$company[id_a] <- "akzo"
df$company[id_v] <- "van houten"
df$company[id_u] <- "unilever"

#Note the (company) proper names above need to stay lowercase 
#or they will break the code which should otherwise work fine. 
#Capitalizing proper names helps with human readability 
#but our instructions for this exercise state that 
#all-lowercase is fine here.
#Now to print a sample from df to confirm our results.
print(df[4:25,1])
```


We could also take advantage of a pattern in first-letters of company name, as in this dataset, they all match to the correct company (note we're mapping both F and P to Philips). Thus, we could correct the misspellings using pipe operators, ifelse statements, and R's startsWith function, since that is a second pattern in the dataset. The code would look like this: 


```{r eval=F}
#Using the First-Letters Approach
#Also capitalizing proper nouns here to help with readability and 
#because the code allows it.
df$company <- ifelse(startsWith(df$company,"p"), "Philips", 
                    ifelse(startsWith(df$company,"a"), "Akzo", 
                    ifelse(startsWith(df$company), "v"), "Van Houten", 
                    ifelse(startsWith(df$company), "u"), "Unilever", 
                    ifelse(startsWith(df$company), "f"), "Philips"
```


The "First-Letters Approach" above is more concise than agrep, and doesn't break down if we capitalize company names - is First-Letters a more effective approach than agrep?

I would say no. For most purposes, First-Letters's success is an example of overfitting. In a larger data set, where people start making errors where the first letter doesn't match company name's first letter (such as "Ekzo" for "Akzo" or "Fan Houten" instead of "Van Houten") then the First-Letters breaks down while agrep is still good. 

##2. Separate product code and number 

So now that we have our correct brand names factored and stored in "df," we can move on to task 2, to separate transaction code number from product key. 


```{r}
#2: We can use the separate function to acheive this with one line. 
df <- df %>% separate(Product.code...number, c("product_code", "product_number"), "-")
#Printing a sample to audit from df
print(df[5:25,1:3])
```

##3. Add product categories

The given categories are as follows: 

  - p = Smartphone
  - v = TV
  - x = Laptop
  - q = Tablet
  
We are tasked to add a column for category with the appropriate tag for each row's transaction. 

```{r}
#We will use the grepl function with ifelse and mutate 
#to acheive this and also print our dataframe "df" 
#to confirm the correct result.
df <- df %>% mutate(product_category = 
  ifelse(grepl("p", product_code), "Smartphone",
  ifelse(grepl("v", product_code), "TV",
  ifelse(grepl("x", product_code), "Laptop",
  ifelse(grepl("q", product_code), "Tablet", NA)))))

#Printing the new column for product category
print(df[1:10,8])
```

##4. Add full address for geocoding

To format this data to be able to easily and robustly export to most mapping software at any time or on demand for later users, we can use the following unite command to join the the relevant three columns of address, city, and country into one single geocoded address column we will call "geotag."


```{r}
#Creating geotag column and showing the result. 
#Note we are using a whitespace after the comma to assist with readability.
df <- df %>% unite(geotag, address, city, country, sep=", ")

#Printing relevant columns to confirm the result.
print(df[,3:4])
```

##5. Create dummy variables for company and product category

To make this more usable, we are tasked to create binary variables corresponding to category. 


```{r}
#5: Using one column for each category of product, and company respectively
df <- df %>%
  mutate(product_smartphone = ifelse(grepl("Smartphone", product_category), 1, 0)) %>%
  mutate(product_tv = ifelse(grepl("TV", product_category), 1, 0)) %>%
  mutate(product_laptop = ifelse(grepl("Laptop", product_category), 1, 0)) %>%
  mutate(product_Tablet = ifelse(grepl("Tablet", product_category), 1, 0)) %>%

#Again using four columns since there are four company tags
  mutate(company_philips = ifelse(grepl("philips", company), 1, 0)) %>%
  mutate(company_akzo = ifelse(grepl("akzo", company), 1, 0)) %>%
  mutate(company_van_houten = ifelse(grepl("van houten", company), 1, 0)) %>%
  mutate(company_unilever = ifelse(grepl("unilever", company), 1, 0))

#Printing some relevant binary columns to confirm the result.
print(df[,6:9])
```

##6. Submit the paper on Github

I will submit this manually on Github after exporting the new df as a .csv file. 

```{r}
#As instructed, the new data file is named "refine_clean.csv" 
write.csv(df, "refine_clean.csv", row.names=F)
```

Thanks for reading!